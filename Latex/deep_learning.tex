\chapter{Deep Learning}

\section{Redes Neuronales Prealimentadas}

Las \textbf{redes neuronales} son el ejemplo más típico de modelos de Deep Learning. El objetivo de esta clase de algoritmos es aproximar una función $f^*$. Por ejemplo, para un clasificador $y = f^*(x)$ que asocia a cada entrada $x$ una categoría $y$. Así, una red neuronal prealimentada define una asociación $y = f(x; \theta)$ y aprende los valores de los parámetros $\theta$ que ofrecen la mejor aproximación de la función.

Esta clase de modelos se llaman \textbf{prealimentados} porque la información fluye desde la función siendo evaluados desde $x$, mediante los cálculos intermedios usados para definir $f$ y finalmente hasta la salida $y$. 

Las redes neuronales son llamadas \textbf{redes} pues se definen mediante la composición de diferentes funciones. Este modelo de sucesivas composiciones se puede ver como un grafo dirigido acícilo. 

El número de capas que tenga la red definen la \textbf{profundidad} del modelo. Las capas se van nombrando de forma sucesiva siendo la primera la primera capa o \textit{capa de entrada}, \textit{segunda capa}, y así sucesivamente hasta la capa final denominada \textit{capa de salida}. El objetivo del modelo es conducir la función de entrada $f(x)$ para que se ajuste a $f^*(x)$. 

\section{Redes Neuronales Convolucionales}



\section{Redes Neuronales Recurrentes}

\subsection{Long-Short Term Memory}