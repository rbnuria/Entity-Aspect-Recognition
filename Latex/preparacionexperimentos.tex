\chapter{Preparación de los experimentos} \label{preparacionexperimentos}
%TODO poner aquí las secciones
%TODO avisar también de qué he hecho en R, qué en C++, etc.
En este capítulo se explicará el procedimiento para la realización de los experimentos. En la Sección \ref{toolsanalysis} se hablará de las herramientas, de cómo se han realizado los experimentos con estas y qué aspectos se han tenido en cuenta, así como de los \textit{datasets} empleados para la experimentación. Posteriormente se explicará el proceso completo para la búsqueda de pesos con el fin de optimizar las tasas e error en los distintos conjuntos de datos (Sección \ref{evolutionpreparation}).

%TODO Métricas
\section{Análisis de las herramientas} \label{toolsanalysis}
En esta sección se presentará un resumen de los conjuntos de datos empleados (Sección \ref{datasets}) para la experimentación y hablaremos de cada herramienta individualmente más en detalle y cómo se han realizado los experimentos con cada una de estas en la Sección \ref{toolsdescription}. Posteriormente, en la Sección \ref{ensamble} se explicarán las dos estrategias de ensamblado usadas y finalmente, en la Sección \ref{metricas} se explicarán las métricas que se emplearán para la comparación de herramientas.

\subsection{Conjuntos de datos} \label{datasets}
Los conjuntos de datos han sido proporcionados por Matheus Araújo y su equipo de investigación. Son los mismos conjuntos de datos con los que ellos realizaron su estudio en \cite{rib}. Se tratan de 18 conjuntos de datos tomados de distintas fuentes, como podemos ver en la tabla \ref{tabla_datos}. El etiquetado de los comentarios ha sido realizado por humanos, Amazon Mechanical Turk \footnote{https://www.mturk.com/mturk/welcome} (AMT) o, como en los casos de comentarios valorando películas, mediante la valoración dada por el usuario a la propia película. Todos los conjuntos de comentarios están etiquetados como \textit{positive}, \textit{negative} y \textit{neutral}, aunque algunos no contienen comentarios con esta última etiqueta.

%TODO explicar los conjuntos de datos individualmente
Entre los conjuntos de datos se ve diversidad en los contextos en los que los comentarios se realizan. Hay tweets en contextos concretos (como los de debate político), tweets cogidos aleatoriamente, valoraciones de películas, comentarios en vídeos de YouTube o evaluaciones sobre productos en Amazon. Hay otros conjuntos de comentarios que son en contextos concretos, como por ejemplo sentistrength\_bbc, vader\_nyt y sentistrength\_digg que son comentarios de gente en determinados foros de discusión sobre noticias en el diario BBC, \textit{New York Times} y la revista Digg. Al tratarse de hilos de comentarios, estos comentarios dependen de los anteriores, por lo que aunque sean sobre dominios concretos, la polaridad podría depender de otros comentarios, dificultando la extracción de polaridad incluso por la parte del experto. 


En la Tabla \ref{tabla_datos}, además, también se puede observar el número de comentarios de cada conjunto, cuántos son positivos, negativos o neutros, la media de frases por comentario, la media de palabras por comentario y también cómo nos referiremos a estos conjuntos de datos en el proyecto (nombre de los ficheros de datos).

\newpage
	\begin{table}[H] 
		\small
		\scalebox{0.7}{
	\begin{tabular}{|b{1.8cm}b{1.3cm}b{1.3cm}b{1.3cm}b{1.3cm}b{1.5cm}b{1.9cm}c|}
		\hline		
		\rowcolor{lightgray} 
		\textbf{Dataset} &  \textbf{Msg} & \textbf{Pos} & \textbf{Neg} & \textbf{Neu} & \textbf{Media frases} & \textbf{Media palabras} & \textbf{Nombre fichero} \\ 
		\hline  
		Comments (BBC)& 1000 & 99 & 653 & 248 & 3.9 & 64.39  & sentistrength\_bbc  \\ 
		\hline 
		Comments (Digg) & 1077 & 210 & 572 & 295 & 2.5 & 33.97 & sentistrength\_digg \\ 
		\hline 
		Comments (NYT) & 5190 & 2204 & 2742 & 274 & 1.01 & 17.76 & vader\_nyt \\ 
		\hline 
		Comments (TED) & 839 & 318 & 409 & 112 & 1 & 16.95 & nikolaos\_ted \\ 
		\hline 
		Comments (Youtube)& 3407 & 1665 & 767 & 975 & 1.78 & 17.68  & sentistrength\_youtube  \\ 
		\hline 
		\specialcell{Movie\\reviews} & 10662 & 5331 & 5331 & - & 1.15 & 18.99  & pang\_movie    \\ 
		\hline 
		\specialcell{Movie\\reviews} & 10605 & 5242 & 5326 & 37 & 1.12 & 19.33   & vader\_movie   \\ 
		\hline 
		Myspace posts & 1041 & 702 & 132 & 207 & 2.22 & 21.12  & sentistrength\_myspace  \\ 
		\hline 
		Product Reviews (Amazon) & 3708 & 2128 & 1482 & 98 & 1.03 & 16.59  & vader\_amazon   \\ 
		\hline 
		Tweets (Debate)& 3238 & 730 & 1249 & 1259 & 1.86 & 14.86 & debate  \\ 
		\hline 
		Tweets (Random)& 4242  & 1340 & 949 & 1953 & 1.77 & 15.81  & sentistrength\_twitter   \\ 
		\hline 
		Tweets (Random)& 4200 & 2897 & 1299 & 4 & 1.87 & 14.10  & vader\_twitter  \\ 
		\hline 
		Tweets (Random)& 3771 & 739 & 488 & 2536 & 1.54 & 14.32  & english\_dailabor  \\ 
		\hline 
		Tweets (Random)& 500 & 139 & 119 & 222 & 1.90 & 15.44 & aisopos\_ntua    \\ 
		\hline 
		\specialcell{Tweets\\(Specific\\Domains)}& 359 & 182 & 177 & - & 1.0 & 15.1  & stanford\_tweets   \\ 
		\hline 
		\specialcell{Tweets\\(Specific\\Topics)}& 3424  & 580 & 654 & 2503 & 1.6 & 15.03  & sanders   \\ 
		\hline 
		\specialcell{Tweets\\(SemEval\\2013)}& 6087 & 2223 & 837 & 3027 & 1.86 & 20.05  & tweet\_semevaltest    \\ 
		\hline 
		\specialcell{Runners\\World\\Forum}& 1046 & 484 & 221 & 341 & 4.79 & 66.12  & sentistrength\_rw   \\ 
		\hline 
	\end{tabular}
}
	\caption{Tabla resumen de los \textit{datasets} usados para la experimentación}
	\label{tabla_datos}
\end{table}

\subsection{Métodos de análisis de sentimientos} \label{toolsdescription}
En esta subsección se describirá cada herramienta de extracción de polaridad y cómo se han realizado los experimentos con estas. Además, cada herramienta nos da una salida distinta, por lo que se tienen que normalizar las salidas con el fin de realizar una comparativa entre ellas y posteriormente analizar su comportamiento de forma ensamblada. Las salidas han sido normalizadas en el intervalo [0,1] y para analizar sus tasas de acierto con respecto al etiquetado experto, se han aplicado las etiquetas de la siguiente manera según la intensidad de la polaridad, siendo $x$ la intensidad:
\begin{itemize}
	\item \textbf{Negativa} si $0 \leq x \leq 0.33$
	\item \textbf{Neutra} si $0.33 < x \leq 0.66$
	\item \textbf{Positiva} si $0.66 < x \leq 1$
\end{itemize}

\subsubsection{CoreNLP}
 \textbf{\textit{Standford} CoreNLP} \cite{corenlppaper} es un software desarrollado por la Universidad de Standford que ofrece un paquete de herramientas de análisis de lenguaje natural, como por ejemplo la categorización gramatical de las palabras o la obtención del sentimiento que una frase transmite. Además, ofrece funcionalidad para varios idiomas, aunque para algunas herramientas, como la de análisis de sentimientos, solo admiten el inglés.
 
 La herramienta de análisis de sentimientos se basa en un modelo de aprendizaje automático, más concretamente una red neuronal, como se puede leer en \cite{corenlpfuncionamiento}. Para obtener este modelo han usado un conjunto de datos de comentarios sobre películas los cuales han separado en frases y han obtenido el etiquetado experto de cada frase empleando AMT.
 
 CoreNLP es una herramienta que nos da la polaridad a nivel de frase. Además nos ofrece una salida categórica, donde las etiquetas son \textit{very negative, negative, neutral, positive} y \textit{very positive}. Para obtener el sentimiento numérico total del comentario, averiguo el sentimiento medio haciendo la media de las polaridades de cada frase del comentario. La normalización de la salida se ha realizado asignando los siguientes valores a cada una de las etiquetas para cada frase:
 \begin{itemize}
 	\item 0 si la etiqueta es \textit{very negative}.
 	\item 0.25 si la etiqueta es \textit{negative}.
 	\item 0.5 si la etiqueta es \textit{neutral}.
 	\item 0.75 si la etiqueta es \textit{positive}.
 	\item 1 si la etiqueta es \textit{very positive}.
 \end{itemize}

Para usar CoreNLP se ha usado la librería coreNLP de R. Siguiendo las instrucciones de la documentación dentro del GitHub \cite{corenlpgithub} de esta librería, he implementado la siguiente función en R, que será aplicada sobre cada uno de los conjuntos de datos.

\begin{lstlisting} [language = R]
 obtenerSentimiento <- function(datos)
 {
  comments.datos <- lapply(datos, c)
  comments.datos <- lapply(comments.datos, annotateString)
  sentiments.datos <- lapply(comments.datos, getSentiment)
  label.datos <- sapply(sentiments.datos, assign.polarity)
  return(unlist(label.datos))
 }
\end{lstlisting}

Donde la función assign\_polarity será la que asigne la polaridad media a cada comentario.

%TODO poner aquí las funciones en R así como la de asignación de etiqueta, mejorar el código

\subsubsection{Azure Text Analytics}
Se trata de una API de Microsoft Azure con fines comerciales pero que aún así ofrece una versión de prueba gratuita con hasta 5000 llamadas de la función para obtener el sentimiento. Además de análisis de sentimiento, este software tiene otras herramientas tales como la detección de \textit{topics} o temas o detección de idiomas. Al tratarse de una herramienta comercial, no hay gran información sobre cómo se implementa la clasificación de los comentarios, aunque en su documentación \cite{azuredoc} se menciona que usa técnicas de clasificación, tomando como características de entrada '\textit{n-grams}' de palabras (que son conjuntos de $n$ palabras) y características generadas mediante técnicas de \textbf{\textit{POS}}  y \textbf{\textit{Stemming}}. La salida de la herramienta de análisis de sentimiento nos devuelve un valor en [0,1], por lo que no ha tenido que ser normalizada, indicando un sentimiento cercano a 1 un sentimiento positivo y cercano a 0 un sentimiento negativo.

Para utilizar esta API se ha usado la biblioteca mscstexta4r para R. Antes es necesario crear una cuenta en los servicios de \textit{Machine Learning} de Microsoft, donde obtendremos una clave que debemos declarar como variable de entorno del sistema. Después solo hay que inicializar el entorno con la función textaInit y ya ejecutar la función textaSentiment introduciéndole como argumentos el conjunto de datos en forma de Array y un Array con el idioma de los comentarios repetidos tantas veces como comentarios haya en nuestro fichero. La función textaSentiment acepta en una ejecución un máximo de 500 comentarios por lo que hay que realizar división de algunos conjuntos de datos.

\subsubsection{MeaningCloud}
MeaningCloud \cite{meaningclouddoc} es también una herramienta con fines comerciales. Nos ofrece unas 40.000 consultas de polaridad mensualmente en la tarifa gratuita, aunque también ofrece licencias especiales para estudiantes. Su funcionamiento se basa tanto en el análisis morfo-sintáctico de los textos así como en la utilización del significado de las palabras (diccionarios) para identificar intensidades. Además, esta herramienta es muy flexible ya que nos permite crear nuestros propios diccionarios para la extracción de información de los textos, nuestros propios modelos de clasificación de textos, e incluso nuestros propios modelos de sentimiento para adaptar el análisis de polaridad a nuestro dominio, añadiendo conjuntos de comentarios con su etiquetado para el aprendizaje.

La salida de este software, la cual es a nivel de documento, nos devuelve 6 valores discretos, aunque uno de ellos, \textit{NONE}, indica que el comentario no emite ningún sentimiento, por lo que \textit{NONE} lo consideramos como neutral. Así, se nos quedan 5 valores discretos igual que en CoreNLP, por lo que el paso a valor numérico y normalización en [0,1] es la misma que para CoreNLP.

Para realizar los experimentos primero tenemos que crear una cuenta en MeaningCloud y obtener una clave para la utilización de los servicios del software. Después, en R, generamos una url (https://api.meaningcloud.com/sentiment-2.1?key= $<$ clave $>$ \&of=json\&txt= $<$ comentario $>$ \&lang=en) y mediante una petición POST con la librería \textit{httr} recibimos un JSON, del que solo necesitamos el elemento \textit{score\_tag}.

\subsubsection{SentiStrength}
Este software es también una herramienta de análisis de sentimiento con fin comercial pero con una versión java gratuita para investigación académica. SentiStrength (\cite{senti} y \cite{senti2}) es una herramienta que se basa en un diccionario de palabras que expresan sentimiento con un valor asociado que mide la intensidad de ese sentimiento, empleando además aprendizaje automático para optimizar este diccionario e información lingüística y reglas adicionales.

SentiStrength nos da la salida a nivel de documento y devuelve 2 valores de salida: uno que nos dice cómo de positivo es el comentario y otro que nos dice cómo de negativo es. Para el valor positivo nos devuelve valores discretos y enteros en [1,5], indicando 1 que el comentario no expresa nada de sentimiento positivo y 5 que expresa un sentimiento muy positivo; para el valor negativo la salida es igual a excepción de que esta son valores negativos.

Este software ha sido el más fácil de usar, ya que gracias a la versión java gratuita para investigación en educación (amablemente facilitada por Mike Thelwall, así como sus diccionarios más actualizados), lo único que hay que hacer es ejecutarla introduciéndole como argumentos el fichero de comentarios y los datos o diccionarios.

Para normalizar la salida y equipararla a la de las demás, lo que se ha realizado en este proyecto es obtener la suma de la polaridad positiva y la negativa. Así, el valor negativo indica un sentimiento negativo y el valor positivo un sentimiento positivo. Si es 0, es un sentimiento neutro. Para normalizar esto en [0,1], tenemos que asegurarnos de que un valor negativo esté en el intervalo [0,0.33] y que un valor positivo esté en el intervalo (0.66,1]. Para ello se emplea la siguiente fórmula:

Siendo:
\begin{itemize}
	\item $[a,b]$ el intervalo en el que quiero normalizar.
	\item $[min, max]$ el intervalo en el que se encuentra la salida (positiva o negativa). Por ejemplo, para la positiva $min$ sería 1 y $max$ sería 4.
	\item $x$ el valor de la intensidad de la actual instancia o comentario.
	\item $f(x)$ el nuevo valor de la polaridad ya normalizado.
\end{itemize}

Entonces:
$$ f(x) = [ (b-a)(x-min) / (max - min) ] + a$$

\subsubsection{VADER}
VADER \cite{vader} (\textit{Valence Aware Dictionary and sEntiment Reasoner}) es un SAM basado en diccionario y en reglas que está especialmente ajustado para funcionar bien con textos de los medios de comunicación y \textit{tweets}. Su salida, a nivel de documento, es devuelta en el intervalo [-1,1] siendo 1 lo más positivo posible y -1 lo más negativo posible. Debemos coger de su salida el componente '\textit{compound}', que contiene la valoración global del comentario. La normalización se puede realizar mediante una normalización min-max normal, ya que en este caso no hay que tener en cuenta aspectos como en SentiStrength, Bing o Syuzhet.

Para realizar los experimentos con este software, hay que instalar primero python y el software de VADER, siguiendo las instrucciones de la documentación. Posteriormente, he tomado como referencia un código aportado por Matheus Araújo y disponible en el repositorio \footnote{https://bitbucket.org/matheusaraujo/sentimental-analysis-methods} del equipo de investigación. Para ejecutarlo solo he tenido que ejecutar mediante python el ficher vader.py con el argumento -f $<$fichero$>$.

\subsubsection{Bing y Syuzhet}
Aunque se tratan de dos SAM distintos \cite{syuzhet}, los describiré juntos ya que ambos han sido utilizados mediante la misma biblioteca de R. Ambos SAM son basados en diccionarios. Bing es un diccionario desarrollado por Minqing Hu y Bing Liu, mientras que el diccionario syuzhet fue desarrollado en \textit{Nebraska Literary Lab} bajo la dirección de Matthew L. Jockers.

La salida de ambas herramientas es a nivel de frase, por lo que para obtener la polaridad global del comentario se ha realizado haciendo una media aritmética de las polaridades de cada frase. Los 2 SAMs devuelven valores que no tienen por qué estar en un intervalo concreto, pero los autores afirman que si la salida es negativa entonces el sentimiento es negativo y si es positiva es positivo. Por lo tanto la salida de los comentarios han sido normalizadas con una normalización min-max en la que además hay que tener en cuenta los aspectos tenidos en cuenta con SentiStrength, donde todo valor negativo debe encontrarse en [0,0.33] y todo valor positivo en (0.66,1].

Para ejecutar ambas herramientas he usado el paquete syuzhet para R. La función para obtener el sentimiento es muy parecida a la de coreNLP:
\begin{lstlisting} [language = R]
obtenerSentimiento <- function(datos)
{
 comments.datos <- lapply(datos, c)
 comments.datos <- lapply(comments.datos, get.sentences)
 sentiments.datos <- lapply(comments.datos, get.sentiment,
    method="method")
 label.datos <- sapply(sentiments.datos, assign.polarity)
 return(unlist(label.datos))
}
\end{lstlisting}

Donde la función assign\_polarity será la que asigne la polaridad media a cada comentario y method será 'bing' o 'syuzhet' dependiendo del método que se vaya a emplear.

\subsection{Análisis del ensamblado de las herramientas} \label{ensamble}
Como preámbulo de la optimización mediante asignación de pesos del funcionamiento conjunto de las herramientas, se va a realizar un análisis de cómo estas herramientas funcionan de forma ensamblada. Se realizarán dos modelos distintos, descritos a continuación:
\begin{itemize}
	\item \textbf{Sentimiento promedio.} Es el modelo más intuitivo y consiste en asignar la polaridad media teniendo en cuenta la polaridad devuelta por todas las herramientas. De esta manera, la polaridad $P(X)$ se describe como se expresa a continuación:
	$$P(x) = \frac{1}{N}\sum_{i=1}^{N}p_i$$
	Donde $p_i$ es la polaridad devuelta por la herramienta $i$ y $N$ el número de herramientas.
	\item \textbf{Ensamblado proneutral.} Basándonos en el estudio en \cite{proneu}, donde este operador obtiene los mejores resultados del estudio, se empleará este operador con el fin de dar más peso a las herramientas que ofrece una polaridad más neutra. Para el cálculo de pesos para cada instancia, primero se obtienen unos $e_i$ que vienen definidos por $e_i = 1-|p_i-0.5|$ donde $p_i$ es la polaridad dada por por la herramienta $i$ para esa instancia. A partir de estos $e_i$ se obtienen los pesos $w_i$ mediante la expresión: 
	$$w_i=\frac{e_i}{\sum_{j=1}^{N}e_j}$$ donde $N$ es el número de herramientas. A partir de estos pesos se obtiene el sentimiento global del comentario:
	$$P(x)=\sum_{i=1}^{N}w_ip_i$$
\end{itemize}

\subsection{Medidas empleadas para el análisis}  \label{metricas}
Para la comparación de las distintas herramientas emplearemos varias medidas que indican la calidad de la predicción. Estas medidas son las siguientes:
\begin{itemize}
	\item \textbf{Error de clasificación.} Se trata del cociente del número de instancias mal clasificadas entre el número total de instancias. Es una de las medidas más importantes en nuestro análisis y la más intuitiva.
	\item \textbf{Área bajo la curva (\textit{Area Under Curve o AUC}).} El área bajo la curva se puede interpretar como la probabilidad de que un clasificador puntúe una instancia positiva elegida aleatoriamente más alta que una negativa, es decir, que el clasificador la considere 'más positiva' que la negativa. El AUC solo se puede calcular en problemas de clasificación con 2 clases. Al tratarse este un problema de 3 clases, calcularemos la AUC siguiendo una estrategia \textit{one vs all} que consiste en considerar una clase como positiva y el resto como negativas y calcular el AUC, realizando esto para cada clase. El AUC final sería la media de las AUCs. Para calcular el AUC multiclase empleo la función multiclass.roc de la librería pROC, que ya implementa la estrategia explicada.
	\item \textbf{\textit{Recall.}} El \textit{recall} se trata del cociente del número de instancias de una clase acertadas entre el número total de elementos de esa clase o, más formalmente, $Recall = \frac{tp}{tp+fn}$ donde $tp$ (True Positive) es el número de instancias positivas bien clasificadas y $fn$ (False Negative) es el número de instancias predichas como negativas pero en realidad son positivas.
	\item \textbf{Precisión.} La precisión es el cociente entre el número de instancias de una clase correctamente clasificadas entre el número total de instancias que se han clasificado con esa clase. Formalmente se define como $Precision = \frac{tp}{tp+fp}$ donde $fp$ son las instancias clasificadas como positivas pero que en realidad son negativas.
\end{itemize}

Estas últimas medidas (\textit{recall} y precisión) se han usado con el fin de contrastar y matizar más los resultados que se obtienen con las AUCs.

\begin{figure} [H]
	\centering
	\includegraphics[width=0.4\linewidth]{imagenes/precisionrecall}
	\caption{Explicación gráfica de qué son el Recall y la precisión. Fuente: Wikipedia}
	\label{fig:precisionrecall}
\end{figure}


\section{Optimización mediante algoritmos evolutivos} \label{evolutionpreparation}
En esta sección se describirá primero el procedimiento general para la optimización (Sección \ref{preparacionevo}), tanto la preparación de los ficheros de datos como el tipo de validación que se empleará. También se describirán los algoritmos (Sección \ref{algorithms}) evolutivos que se emplearán, describiendo detalladamente tanto sus componentes como su pseudocódigo. Finalmente, como se desarrollará software para la ejecución de los algoritmos, en la Seccion \ref{is} se realizará una sección para detallar un poco más las funciones auxiliares a los algoritmos y la utilización del programa.
\subsection{Preparación de datos y validación} \label{preparacionevo}
La ejecución de las metaheurísticas se realizará sobre los resultados continuos que hemos obtenido de la ejecución de las herramientas. Para ello, mediante un script en R, crearemos un fichero de datos para cada conjunto de datos, cuyas filas representarán cada comentario, teniendo estos 7 características que serán las polaridades de cada herramienta para este comentario y un valor 'etiqueta' que será el sentimiento experto del comentario.

Nuestro algoritmo nos dará una combinación lineal del producto de los pesos buscados por el algoritmo y la intensidad de cada herramienta, tal y como se describe a continuación:
$$P(x) = \sum_{i=1}^{n}w_i*p_i$$
donde:
\begin{itemize}
	\item $P(x)$ es la polaridad final del comentario $x$.
	\item $n$ es el número de características, en nuestro caso 7 (una por cada herramienta).
	\item $w_i$ es el peso que nuestro algoritmo asigna a la herramienta $i$, normalizados en $[0,1]$ y tal que la suma de todos los $w_i$ sumen 1.
	\item $p_i$ es el valor de la polaridad de la herramienta $i$ en el comentario $x$.
\end{itemize}

 Todos los algoritmos tendrán en común la función objetivo, es decir, la función que hay que optimizar. La función objetivo es el error cuadrático medio, el cual tendremos que reducir. Este error lo calcularemos con respecto al etiquetado del conjunto de datos de train, es decir, un 80\% de los comentarios (el otro 20\% se empleará posteriormente para la validación). El error cuadrático medio viene definido por la siguiente expresión, siendo $Y'$ un vector de $n$ predicciones e $Y$ un vector que contiene los verdaderos valores:
 $$ECM = \frac{1}{n}\sum_{i=1}^{n}(Y'_i-Y_i)^2$$
 
 La validación para el aprendizaje de los pesos se realizará mediante una validación cruzada \textit{5-fold cross validation}, que consiste en dividir el conjunto de datos en 5 subconjuntos realizando 5 iteraciones donde en cada iteración aprenderemos con 4 subconjuntos y validaremos con uno. Para realizar la valoración de los resultados emplearemos un error de clasificación normal, para así poder dar una mejor interpretación.
 
 Otro aspecto en común de todos los algoritmos es el criterio de parada. Todos los algoritmos evolutivos tendrán como criterio de parada la evaluación de un máximo de 500.000 veces la función objetivo.
 
 \subsection{Descripción de los algoritmos} \label{algorithms}
 En esta sección se describirá cada uno de los algoritmos evolutivos que se emplearán para la optimización. Se describirán tanto las componentes del algoritmo como su funcionamiento y pseudocódigo.
 
 \subsubsection{Algoritmos genéticos}
 Los algoritmos genéticos son algoritmos que están basados en la evolución natural y la evolución genética. Para este proyecto se implementarán dos modelos, que se diferencian en el esquema de evolución:
 \begin{itemize}
 	\item \textbf{Esquema generacional con elitismo}. Por un lado, se considerará un esquema de
 	evolución generacional, esto es, se seleccionaría una generación de padres del mismo tamaño de
 	la población genética que serían posteriormente cruzados y mutados (algunos de ellos). Para
 	mantener el elitismo, nos aseguraremos de que la mejor solución de la población anterior siga
 	apareciendo en la nueva generación. Para ello, si esto no ocurre sustituiremos la peor solución
 	generada en la nueva población por la mejor de la anterior.
 	\item \textbf{Esquema estacionario.} Por otro lado, consideraremos un esquema de evolución estacionario,
 	donde seleccionaremos dos padres que serían posteriormente cruzados y mutados. Los cromosomas resultado del cruce y mutación de los padres generados, sustituirán
 	a los dos cromosomas más débiles de la población anterior (peor función objetivo) en caso de no
 	ser ellos mismos.
 \end{itemize}

La primera generación se generará de forma aleatoria. Para la generación de soluciones aleatorias tenemos que tener en cuenta la restricción de que los pesos deben sumar 1. Para mantener la restricción, generamos el primer peso en el intervalo $[0,1]$ y, a partir de aquí, seguimos generando en el intervalo $[0,1-acumulado\_generados]$, donde $acumulado\_generados$ es la suma de todos los pesos anteriormente generados.
\newpage
Ambos modelos tienen en común el operador de cruce. Se trata del operador \textbf{CA}, u operador de cruce aritmético, que cada dos cromosomas padres, genera un cromosoma hijo fruto de la media aritmética componente a componente de ambos padres, manteniéndose además la restricción de que todos los pesos sumen 1. Por lo tanto, considerando los padres anteriores, el hijo sería de la forma:

$$
c_{hijo} = ( \frac{c_{11} + c_{21}}{2}, ..., \frac{c_{1n} + c_{2n}}{2})
$$
Como este operador genera solo 1 hijo por cada 2 padres, tendremos que utilizar el doble de padres para obtener una población del mismo tamaño que la anterior. En el pseudocódigo \ref{alg:operadorcruce} tenemos la descripción del operador.

También tienen en común el criterio de selección, descrito en el pseudocódigo \ref{alg:opsel}, que se trata de un torneo binario.   Sin embargo, en cada uno de los esquemas se generan un número diferente de padres, por tanto pasamos como argumento el número de torneos que deseamos realizar. No se acepta que compitan dos cromosomas iguales pues podría darse la posibilidad de que pasara a la siguiente generación el cromosoma más débil, por tanto, realizamos tantos randoms como sean necesarios. Además, para no realizar más llamadas a la función objetivo de las necesarias, guardamos en un vector la tasa de acierto para cada solución que tenemos almacenada, llamamos a este vector \textit{fitness}. Se tiene acceso a dicho vector y a la generación sobre la cual estamos trabajando por eso no lo pasamos como argumento.

\newpage
\begin{algorithm}[H]
	\caption{Operador de selección.}
	\label{alg:opsel}
	\begin{algorithmic}[1]
		\Procedure{operador\_selección}{data, num}
		
		\For{ $0 \leq i < num$}
		\State $pos1 \gets$ \texttt{random(0, $size(generation)-1$)}
		\State $pos2 \gets$ \texttt{random(0, $size(generation)-1$)}
		
		\vspace{0.2cm}
		
		\While{$pos1 = pos2$}\Comment{Repetimos hasta obtener dos posiciones distintas}
		\State $pos2 \gets$ \texttt{random(0, $size(generation)-1 $)}
		\EndWhile
		
		\vspace{0.2cm}
		
		\If{\texttt{fitness[pos1]} $>$ \texttt{fitness[pos2]}}\Comment{El ganador pasa a la siguiente generación}
		\State $second\_generation \gets second\_generation + generation[pos1]$
		\State $fitness\_second \gets fitness\_second + fitness[pos1]$\Comment{Guardamos un vector con la tasa de acierto de la nueva generación.}
		\Else
		\State $second\_generation \gets second\_generation + generation[pos2]$
		\State $fitness\_second \gets fitness\_second + fitness[pos2]$				
		\EndIf
		
		\EndFor
		
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\begin{algorithm} [H]
\caption{Operador cruce aritmético}
	\label{alg:operadorcruce}
	\begin{algorithmic}[1]
		\Procedure{CA}{padre1, padre2}
			\For{$0 \leq i < size(padre1)$}
			
				
				\State $hijo[i] = \frac{padre1[i]+padre2[i]}{2}$
			\EndFor
		\EndProcedure
		\end{algorithmic}
\end{algorithm}

La probabilidad de cruce y mutación para cada uno de los modelos serán 0.7 para el cruce y 0.001 por gen generado (cada característica o componente del vector solución es un gen) para la mutación.

El operador de mutación se trata del operador por \textbf{mutación normal},  el cual se describe en el pseudocódigo \ref{alg:operadormutacion}, que consiste en sumar al gen un valor $z$ que se trata de un número aleatorio generado por un generador de números aleatorios, que sigue una función de distribución de probabilidad normal, tal que la media es 0 y la desviación típica $\sigma^2=0.3$. 
\begin{algorithm} [H]
	\caption{Operador mutacion}
	\label{alg:operadormutacion}
	\begin{algorithmic}[1]
		\Procedure{mutate}{cromosoma, gen}
		
\State	$num\_random = dist\_normal(0.0,0.3)$
	
		\State$ cromosoma[gen] = cromosoma[gen] + num\_random$
		
		\State
		\If{$cromosoma[gen] < 0.0$}
		\State $cromosoma[gen] = 0.0$
		\EndIf
		\If{$cromosoma[gen] > 1.0$}
		\State $cromosoma[gen] = 1.0$
		\EndIf
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

Después de la mutación debemos asegurarnos de que en este nuevo cromosoma se mantenga la restricción de que todos los pesos sumen 1. Para ello a cada peso $w_i$ le asignamos el valor $\frac{w_i}{\sum_{j=1}^{n}w_j}$ donde $n$ es el número de características o pesos. A esta función se le llamará $keep\_restriction$, a la que se le introducirá como entrada la el cromosoma mutado. Debido a la simplicidad de la función, no se explicará en pseudocódigo.

\newpage
\textbf{·Pseudocódigos algoritmos genéticos}

A continuación se describen en pseudocódigo los algoritmos genéticos comentados previamente. En el pseudocódigo \ref{alg:aggca} se describe el modelo generacional y en el \ref{alg:ageca} el estacionario.

\begin{algorithm}[H]
	\caption{Algoritmo AGG-CA}
	\fontsize{8}{9pt}\selectfont
	\label{alg:aggca}
	\begin{algorithmic}[1]
		\Procedure{AGG-CA}{train, generation}
		\State $evaluaciones \gets 0$\Comment{Contabilizar llamadas a la función objetivo.}
		\State $num\_cromosomas \gets size(generation), \quad num\_genes \gets size(generation[0])$
		
		
		\For{$0 \leq i < num\_cromosomas$}
		\State$fitness\_first[i] \gets$ \texttt{funcion\_objetivo(train, generation[i])}
		\EndFor
		
		
		\State $nc \gets num\_cromosomas \times 0.7$\Comment{Calculamos las esperanzas matemáticas}
		\State $nm \gets num\_cromosomas \times num\_genes \times 0.001$
		
		\vspace{0.2cm}	
		
		\While{$evaluaciones < 15000$}
		
		\State $best\_solution \gets generation[$\texttt{findMax(fitness\_first)]}\Comment{Localizamos el máximo.}
		\State $best\_fitness \gets fitness\_first[$\texttt{findMax(fitness\_first)]}
		
		\vspace{0.2cm}	
		
		\State $second\_gen, fitness\_second \gets$ \texttt{operador\_seleccion(train, 30)}\Comment{Fase de selección.}
		
		\vspace{0.2cm}	
		
		\State $pos \gets 0$\Comment{Fase de cruce.}
		\If{$nc \quad mod(2) \neq 0$}\Comment{Hacemos par el número de cruces.}
		\State $nc \gets nc + 1$
		\EndIf
		
		\For{$0 \leq i < nc$}\Comment{Almacenamos los cromosomas a cruzar}
		\State $cruces[i] \gets second\_gen[i]$
		\EndFor
		\vspace{0.2cm}	
		
		\For{$0 \leq i < nc, \quad i = i + 2$}\Comment{Primera vuelta de cruces.}
		\State $second\_gen[pos] \gets$ \texttt{CA(cruces[i], cruces[i+1])}
		\State  $fitness\_second[pos] \gets$ \texttt{funcion\_objetivo(train, second\_gen[pos])}
		\State $evaluaciones \gets evaluaciones + 1, \quad pos \gets pos + 1$
		\EndFor
		
		\For{$0 \leq i < nc/2$}\Comment{Segunda vuelta de cruces.}
		\State $second\_gen[pos] \gets$ \texttt{CA(cruces[i], cruces[nc - i -1])}
		\State  $fitness\_second[pos] \gets$ \texttt{funcion\_objetivo(train, second\_gen[pos])}
		\State $evaluaciones \gets evaluaciones + 1, \quad pos \gets pos + 1$
		\EndFor
		
		\For{$0 \leq i < nm$}\Comment{Fase de mutación.}
		\State $crom \gets$ \texttt{random(0, num\_cromosomas -1)}
		\State $gen \gets$ \texttt{random(0, num\_genes - 1)}
		
		\vspace{0.2cm}	
		\State \texttt{mutate(crom, gen)}
		\State \texttt{keep\_restriction(crom)}
		\vspace{0.2cm}	
		\State $fitness\_second[crom] \gets$ \texttt{funcion\_objetivo(train, second\_gen[crom])}
		\State $evaluaciones \gets evaluaciones + 1$
		
		\EndFor
		
		
		\If{$best\_solution \notin second\_gen$}\Comment{Fase de reemplazamiento.}
		\State $second\_gen[$\texttt{findMin(fitness\_second)]} $\gets best\_solution$
		\State $second\_fitness[$\texttt{findMin(fitness\_second)]} $\gets best\_fitness$
		\EndIf
		
		
		\State $generation \gets second\_gen$
		\State $fitness \gets second\_fitness$
		
		\EndWhile		
		
		\Return $generation[$\texttt{findMax(fitness)]}
		
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
%TODO Cambiar el criterio de parada a las iteraciones reales

\begin{algorithm}[H]
	\caption{Algoritmo AGE-CA}
	\fontsize{8}{10pt}\selectfont
	\label{alg:ageca}
	\begin{algorithmic}[1]
		\Procedure{AGE-CA}{train, generation}
		\State $evaluaciones \gets 0$\Comment{Contabilizar llamadas a la función objetivo.}
		\State $num\_cromosomas \gets size(generation), \quad num\_genes \gets size(generetion[0])$
		
		\vspace{0.2cm}	
		
		\For{$0 \leq i < num\_cromosomas)$}
		\State$fitness\_first[i] \gets$ \texttt{funcion\_objetivo(train, generation[i])}
		\EndFor
		
		\vspace{0.2cm}			
		
		\State $nm \gets 2 \times num\_genes \times 0.001$
		\State $iteraciones\_mutacion \gets \frac{1}{nm}$
		
		\vspace{0.2cm}	
		
		\While{$evaluaciones < 15000$}
		\vspace{0.2cm}	
		\State $padre1, padre2, padre3, padre4 \gets$\texttt{operador\_seleccion(train, 4)}\Comment{Fase de selección.}
		\Comment{El método devuelve un vector de 4 padres pero es más fácil verlo así.}
		\vspace{0.2cm}	
		
		\State $hijo1 \gets$\texttt{CA(padre1, padre2)}\Comment{Fase de cruce.}
		\State $hijo2 \gets$\texttt{CA(padre3, padre4)}
		
		\vspace{0.2cm}	
		
		\If{$num\_iter = iteraciones\_mutacion$}\Comment{Fase de mutación.}
		\State $gen \gets$\texttt{random(0, num\_genes - 1)}
		\State \texttt{mutate(hijo1,gen)} \Comment{Mutamos el primero pues es aleatorio.}
		\State \texttt{keep\_restriction(hijo1)}
		\State $num\_iter \gets 0$\Comment{Comenzamos contador.}
		
		\EndIf
		
		\vspace{0.2cm}	
		
		\State $generation \gets generation + hijo1+ hijo2$ \Comment{Fase de reemplazamiento}. 
		\State $fitness \gets fitness +$\texttt{funcion\_objetivo(train, hijo1)} 
		\State $fitness \gets fitness +$\texttt{funcion\_objetivo(train, hijo2)} 
		\State $evaluaciones \gets evaluaciones + 2$
		
		
		\vspace{0.2cm}	
		
		\State $generation \gets generation - generation$\texttt{[findMin(fitness)]}\Comment{Eliminamos los dos peores cromosomas.}
		\State $fitness \gets fitness - fitness$\texttt{[findMin(fitness)]}
		\State $generation \gets generation - generation$\texttt{[findMin(fitness)]}
		\State $fitness \gets fitness - fitness$\texttt{[findMin(fitness)]}
		
		\vspace{0.2cm}	
		
		\State $num\_iter \gets num\_iter + 1$			
		
		\EndWhile		
		
		\vspace{0.2cm}	
		
		\Return $generation[$\texttt{findMax(fitness)]}
		
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsubsection{Evolución diferencial}

	La evolución diferencial (\cite{differentialevo}) es un modelo evolutivo que enfatiza la mutación, usando para ello un operador de cruce posterior a la mutación, favoreciendo de esta manera la exploración del algoritmo. Se trata de un modelo propuesto para la optimización con parámetros reales. Al igual que en los algoritmos genéticos, la primera población será generada de forma aleatoria.
	
	Para cada población generada se irán produciendo hijos utilizando dos operadores que se describirán a continuación. Una vez generado el hijo, este competirá con su padre para ver quién permanece en la generación.

	En este proyecto se considerarán dos tipos de algoritmos evolutivos en función del algoritmo elegido para obtener el vector mutación:
		\begin{itemize}
		\item \textbf{DE/Rand/1: } El vector hijo se obtendrá mediante la siguiente fórmula
		\[
		V_{i,G} = X_{r1,G} + F (X_{r2,G} - X_{r3,G})
		\]
		donde los índices r1 ,r2 y r3 de cada individuo $i$ en cada generación $G$ serán escogidos aleatoriamente de forma mutuamente excluyente (incluyendo al vector i-ésimo).
		
		Observamos el pseudocódigo de este operador en Algorithm \ref{alg:rand}.
		
		\begin{algorithm}[H]
			\caption{Algoritmo de cruce (Rand 1)}
			\label{alg:rand}
			\begin{algorithmic}[1]
				\Procedure{rand}{population, dim, CR, F, i}
				
				\State $p1,p2,p3 \gets $ \texttt{select3Parents(population, i)} \Comment{Obtenemos tres padres.}
				
				\For{$0 \leq j < dim$}
				\If{\texttt{DistribucionUniforme(0,1)} $ < CR$}
				\State $offspring[j] \gets population[p1][j] + F (population[p2][j] - population[p3][j]) $
				\Else
				\State $offspring[j] \gets population[i][j]$
				\EndIf
				
				
				\EndFor
				
				
				\Return $offspring$
				
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
		Donde la función select3Parents selecciona 3 soluciones distintas aleatoriamente de la población y DistribucionUniforme se trata de una función que devuelve un número aleatorio, siguiendo esta función una distribución de probabilidad uniforme.
		
		\item \textbf{DE/Current-to-best/1 :} En este caso, el vector mutación se obtiene a partir de la siguiente fórmula:
		
		\[
		V_{i,G} = X_{i,G} + F(X_{best,G} - X_{i,G}) - F(X_{r1,G} - X_{r2,G})
		\]
		
		Donde, análogamente al operador anterior, los índices $r1$ y $r2$ serán escogidos de forma aleatoria de forma mutuamente excluyente (incluyendo la posición $i$), mientras que $X_{best,G}$ denota el mejor individuo de la población $G$.
		
		Observamos el pseudocódigo en el pseudocódigo \ref{alg:best}.
		
		\begin{algorithm}[H]
			\caption{Algoritmo de cruce (Current to best 1)}
			\label{alg:best}
			\begin{algorithmic}[1]
				\Procedure{best}{population, dim, CR, F, i}
				
				\State $p1,p2 \gets $ \texttt{select2Parents(population, i)} \Comment{Obtenemos tres padres.}
				
				\For{$0 \leq j < dim$}
				\If{\texttt{DistribucionUniforme(0,1)} $ < CR$}
				\State $offspring[j] \gets population[i][j] + F (population[best][j] - population[i]][j]) + F(population[p1][j] - population[p2][j]) $
				\Else
				\State $offspring[j] \gets population[i][j]$
				\EndIf
				
				
				\EndFor
				
				
				\Return $offspring$
				
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
		Donde tenemos las funciones auxiliares Select2Parents (igual que la explicada anteriormente pero seleccionando 2 padres) y DistribucionUniforme, también explicada en el modelo anterior.
	\end{itemize}
	 
	 Hay que destacar que estos 2 operadores de cruce no mantienen la restricción de que los pesos sumen 1, por lo que justo después del cruce también es necesario emplear la función $keep\_restriction$ que se ha descrito en el apartado de algoritmos genéticos.
	
	Como podemos observar, ambos operadores están basados en distancias con una cierta probabilidad. En el caso del primero, acercamos la solución en $p1$ a los otros dos padres, obteniendo así una combinación de estos tres padres en la componente $j$ y, en total, obteniendo el hijo mutado como una combinación de varios padres de la generación anterior. En el segundo caso, lo que hacemos es acercar el padre actual a la mejor solución y luego acercarlo a la combinación de los dos padres. 
	
	Cuando nos referimos a que el cruce se realizará con cierta probabilidad, es que vamos a utilizar una recombinación binomial, esto es, el operador solo se aplicará si al obtener un número aleatorio entre (0,1) se encuentra por debajo de un cierto parámetro $CR$ previamente fijado.
	
	La principal diferencia entre ambos operadores y que observaremos en el análisis de resultados, es que el primero fomenta la exploración, dado que realiza mutaciones más fuertes y totalmente aleatorias, mientras que el segundo fomenta la explotación, explotando la mejor solución hasta el momento generada acercando todos los hijos generados hacia esta solución. En el análisis de resultados, contemplaremos la diferencia \textit{explotación VS exploración}.
	
	El reemplazamiento en ambos algoritmos evolutivos será \textit{one-to-one}. Esto es, cada hijo generado competirá con su padre para sustituirle en la generación. 
	
%TODO terminar los pseudocódigos de differential evolution y seguir hablando de los meméticos	
	El pseudocódigo de ambos algoritmos de evolución diferencial queda resumido en pseudocódigo \ref{alg:ED}. Pasamos como argumento el conjunto de train, la solución por referencia y los siguientes parámetros:
	
	\begin{enumerate}
		\item \textbf{CR: } probabilidad utilizada para la recombinación binomial. En nuestro caso esta probabilidad será de 0.5.
		\item \textbf{F: } constante de proporcionalidad utilizada en los operadores de mutación. Esta constante de proporcionalidad será 0.5.
		\item \textbf{size: } Tamaño de la población inicial (se mantendrá constante durante todo el proceso).
		\item \textbf{max\_iteraciones: } número máximo de llamadas a la función objetivo.
	\end{enumerate}

\newpage
		\begin{algorithm}[H]
		\caption{Evolución diferencial.}
		\label{alg:ED}
		\begin{algorithmic}[1]
			\Procedure{ED}{train,  sol, CR, F, size, max\_iteraciones}
			
			\State $dim \gets size(sol)$
			\State $population \gets$ \texttt{randomPopulation(size, dim)}
			
			\State $best\_fitness, eval \gets 0$ \Comment{Inicialización de variables.}
			
			\For{$0 \leq i < size$}
			\State $fit[i] \gets$ \texttt{funcion\_objetivo(train, sol)} \Comment{Guardamos fitness de la población.}
			\State $eval \gets eval + 1$
			
			\vspace{0.2cm}
			
			\If{$fit[i] > best\_fitness$}
			\State $best\_fitness \gets fit[i]$	
			\State $best\_sol \gets population[i]$			
			\EndIf
			\EndFor
			
			\vspace{0.3cm}
			
			\While{$eval < max\_iteraciones$}
			\For{$0 \leq i < size$}
			\State $offspring \gets$ \texttt{rand(population, dim, CR, F)} or \texttt{best(population, dim, CR, F)} \Comment{Dependiendo del algoritmo de evolución diferencial.}
			
			\vspace{0.2cm}
			\State \texttt{keep\_restriction(offspring)}
			\State $offspring\_fit \gets$ \texttt{funcion\_objetivo(train, offpsring)}
			\State $eval \gets eval + 1$
			
			\vspace{0.2cm}
			
			\If{$offspring\_fit > fit[i]$} \Comment{Si el hijo mejora al padre}
			\State $fit[i] \gets offpring_fit$
			\State $population[i] \gets offpsring$
			\EndIf
			
			\vspace{0.2cm}				
			
			\If{$offspring_fit > best\_fit$} \Comment{Si mejora a la mejor solución generada.}
			\State $best\_fit \gets offpsring_fit$
			\State $best\_sol \gets offspring$
			\EndIf
			
			\EndFor
			\EndWhile
			
			
			
			
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}		
	
	\subsubsection{Modificaciones a los modelos evolutivos}
	Después de los experimentos, comentados más adelante, se decidió realizar algunas modificaciones a los modelos evolutivos (concretamente en los algoritmos genéticos). Estas mejoras son las siguientes:
	\begin{itemize}
		\item \textbf{Reducción progresiva de la reducción de probabilidad de mutación.} Basándonos en la popular metaheurística basada en trayectorias de \textit{Enfriamiento Simulado} (\cite{enfriamiento}), por la cual por cada determinado número de iteraciones la probabilidad de mutación se va 'enfriando', es decir, se va reduciendo, se comenzará con una probabilidad de mutación alta, concretamente 0.5 por gen, y por cada etapa esta probabilidad se irá reduciendo en un 10\%.
		\item \textbf{Truncamiento de pesos.} Con esta modificación lo que se pretende es que herramientas cuyos pesos sean muy cercanas a 0, en nuestro caso pesos menores de 0.1, obtengan directamente peso 0, ya que si obtienen un peso muy cercano a 0 probablemente suponga una introducción de ruido.
		\item \textbf{Algoritmos meméticos.} Se tratan de algoritmos genéticos (en este caso se implementa el esquema generacional) que aplica búsqueda local sobre los individuos de la población. Se implementan 3 modelos, \textbf{AM(10,1.0)}, en el que cada 10 generaciones se aplica búsqueda local a todos los los individuos; \textbf{AM (10, 0.1)}, que consiste en aplicar cada 10 generaciones la búsqueda local al 10\% de los individuos elegidos aleatoriamente, y \textbf{AM (10, 0.1 MEJ)}, que aplica la búsqueda local cada 10 generaciones al 10\% mejores cromosomas.
	\end{itemize}

\subsection{Descripción de otras componentes del software} \label{is}
En esta sección se documentará otras partes secundarias del software desarrollado para la realización de los experimentos para la optimización conjunta de las herramientas. Previamente se ha de comentar que todo el software ha sido desarrollado en C++. Además, todos los experimentos para estar en igualdad de condiciones tienen la misma inicicialización de la semilla para el generador de números aleatorios. Primero se empezará con una descripción de los requisitos funcionales del software y posteriormente se realizará una descripción de las funciones que no son los algoritmos ya descritos anteriormente.

\subsubsection{Requisitos funcionales}
Los requisitos funcionales tratan de lo que nuestro software debe ser capaz de realizar respecto a la funcionalidad del mismo. Como se trata de un software cuyo fin es la realización de experimentos para utilización personal los requisitos son bastante básicos.
\begin{itemize}
	\item Como principal requisito, el software debe optimizar el error cuadrático medio asignando pesos a distintas características (que son las polaridades de las herramientas) que posteriormente se combinarán linealmente.
	\item El software debe ser capaz de leer un fichero estructurado con una estructura específica.
	\item El usuario podrá elegir el algoritmo que se empleará así como el conjunto de datos sobre el que queremos encontrar los pesos.
	\item Se imprimirán en pantalla los resultados en cada iteración y las soluciones promedio.
	\item Se lanzarán mensajes de error en el caso de que el usuario no introduzca adecuadamente los argumentos del programa o en caso de que las estructuras de los ficheros no sea adecuada.
\end{itemize}

\subsubsection{Descripción funciones}
Al haber empleado programación funcional en lugar de orientada a objetos, se hará descripción de las funciones más relevantes, sin tener en cuenta las ya descritas en pseudocódigo en la descripción de cada algoritmo.

He aquí la descripción de las funciones:
\begin{itemize}
	\item \textbf{void readFile(char * file\_name, vector $<$Instance$>$ data)}.
	Esta función se encarga de recorrer el fichero con nombre file\_name y guardar las instancias en un vector de Instance.
	\item \textbf{float fitness(vector$<$Instance$>$ \& data, vector $<$float$>$ \& sol)}
	Función que implementa la función objetivo descrita previamente (optimización del ECM). Recibe un vector de Instance que serán las instancias y un vector de flotantes que representará la solución (los pesos).
	\item \textbf{float clasification\_fitness(vector$<$Instance$>$ \& data, vector $<$float$>$ \& sol)}
	Función que nos devuelve el error de clasificación con el que posteriormente valoraremos e interpretaremos los resultados. Recibe mismos argumentos que la función\textbf{fitness}.
	\item \textbf{void partitionate(vector$<$Instance$>$ \& data,vector$<$ vector$<$Instance$>$ $>$ \& sets)}
	Función que particiona el conjunto de datos en 5 subconjuntos para poder realizar la validación cruzada descrita anteriormente.
	\item \textbf{void keep\_restriction (vector $<$float$>$ \& sol)}
	Mantiene la restricción de que todos los pesos del vector solución estén en $[0,1]$ y que la suma de todos los pesos sea 1.
	\item \textbf{vector $<$float$>$ generateRandomSolution()}
	Genera una solución (array de pesos) aleatoria.
	\item \textbf{void exe(vector $<$Instance$>$ \& train, vector $<$Instance$>$ \& test, float \& tasa, float \& time, float \& t\_train, int alg)}
	Esta función recibe el conjunto de training (train), el de test (test) y el algoritmo que se ejecutará (alg) y devuelve por referencia la tasa de error en el conjunto de test (test), la tasa en conjunto de training (t\_train) y el tiempo de ejecución (time).
\end{itemize}
La clase Instance se trata de un struct que contiene un vector de flotantes que representa las características de cada instancia (las polaridades de cada herramienta) y un float que representa la etiqueta (0 es negativo, 0.5 neutro y 1 positivo).

El programa se ejecutará introduciendo como argumentos un entero que representará el algoritmo que se quiere ejecutar y el nombre del fichero que contiene los datos. Los enteros de los algoritmos son 1 para AGG, 2 para AGE, 3 para DE-Rand, 4 DE-Current-To-Best, 5 AGG-Truncate, 6 AGG-SA, 7 AGE-Truncate, 8 AGE-SA, 9 AM(10,1), 10 AM(10,0.1) y 11 AM(10,0.1MEJ).